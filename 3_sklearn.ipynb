{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1f750a",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ac879",
   "metadata": {},
   "source": [
    "> A computer program is said to learn from **experience** E with respect to some class of **tasks** T and **performance measure** P, if its performance at tasks in T , as measured by P , improves with experience E.\n",
    "\n",
    "Tom Mitchell, “Machine Learning”, McGraw-Hill, 1997"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad5121",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8397f",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **Classification**: determining which of a finite set of categories an input belongs to.\n",
    "- **Regression**: inferring the relationship between input and output in order to predict a numerical value given some input.\n",
    "- **Clustering**: discover groups of similar examples within the data\n",
    "- **Density estimation**: determine the distribution of data within the input space\n",
    "- **Synthesis and Sampling**: generate new examples that are like the ones that compose the machine’s experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c45f1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d545a",
   "metadata": {
    "tags": []
   },
   "source": [
    "the dataset the machine accesses to learn how to perform the task. The experience therefore depends on the type of task\n",
    "- In **Supervised Learning**, the dataset contains the labels representing the ground truth from which the machine can learn. \n",
    "- In **Unsupervised Learning**: the dataset is a collection of examples with no additional information. Used to learn the properties or the structure in the data \n",
    "- In **Reinforcement Learning** the machine continuously learn by interacting with the environment.\n",
    "\n",
    "In general, the dataset is split in two part:\n",
    "- **Training set**: used to teach the model so it is the one that composes the actual experience of the machine.\n",
    "- **Test set**: it is used to assess the model performance. For a fair assessment the performance must be measured on examples that are not part of the experience so that are not used during the training.\n",
    "- **Validation set**: sometimes, there is the need for tuning some hyper-parameter (parameter that cannot be trained with the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c0686",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Performance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968e383",
   "metadata": {},
   "source": [
    "A machine needs a quantitative measure to assess how well it is doing. \n",
    "- It is often _task-specific_. For instance, accuracy is ok for classification but useless for regression\n",
    "- It must be _indicative for the desired behaviour_. An algorithm that has the same task and learns from the same experience can have completely different behaviours if different measures are adopted.\n",
    "\n",
    "In general, the measure used to learn (during training) may be different from the one used to assess the performances (test). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301371e",
   "metadata": {},
   "source": [
    "## scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5896c",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "[`scikit-learn`](https://scikit-learn.org/stable/index.html) is a Python package implementing Machine Learning methods for data analysis and designed to be simple and efficient. It is open source, commercially usable and build on top of `numpy`, `scipy`, and `matplotlib`. Not only `scikit-learn` supports supervised and unsupervised learning but also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# modules for random number generation\n",
    "from numpy import random\n",
    "\n",
    "# modules for data visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b547b",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0f6f5",
   "metadata": {},
   "source": [
    "Let's start with a toy case, where we create a dataset with a given model and then we use a `LinearRegression` model available in `scikit-learn` to see if it is able to learn the true relationship between input and ouput from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312dd4a",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0078f",
   "metadata": {},
   "source": [
    "First, we need to build a dataset starting from a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff0dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function implementing the true model\n",
    "def groud_truth(x):\n",
    "    y = 4*x + 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f83a6",
   "metadata": {},
   "source": [
    "Once we have the model we can generate some random input data `x` and compute the labels (or targets) `y` which in general are affected by noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c1aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100 # number of samples to generate\n",
    "x = random.rand(n_samples) # randomly generate samples\n",
    "y_gt = groud_truth(x) # noise-less observations\n",
    "\n",
    "noise = random.randn(n_samples)  # additive noise affecting the observations\n",
    "y_true = y_gt + noise # actual observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af3c18",
   "metadata": {},
   "source": [
    "Here a visualization of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aafba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(x, y_true, c='C0', label='samples')\n",
    "ax.plot(x, y_gt, c='C1', lw=2, label='model')\n",
    "ax.set(xlabel='$x$', ylabel='$y$')\n",
    "ax.legend()\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd008284",
   "metadata": {},
   "source": [
    "### Performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8671c",
   "metadata": {},
   "source": [
    "Before we delve into the machine learning, let us recall that we need a performance measure to say if the machine is doing good or not. A typical measure for Regression problem is the **Mean Squared Error** (**MSE**) that is the mean of the squared errors computed as the difference between the prediction and the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b18239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33eae9",
   "metadata": {},
   "source": [
    "We can compute the MSE for the true model so that it will be a reference for our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_gt = mean_squared_error(y_true, y_gt)\n",
    "mse_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f8bc6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa045f1",
   "metadata": {},
   "source": [
    "We need an estimator that implements the model and is able to learn the parameters from the data that make it perform best.\n",
    "\n",
    "`scikit-learn` provides dozens of built-in machine learning algorithms and models for regression problem. We here start by considering the `LinearRegression` model which finds the linear function that minimizes the square of the prediction error (that is why this kind of problem is called **Ordinary Least Squares**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de078599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the Linear Regression Esstimator\n",
    "reg = LinearRegression() \n",
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854be0b8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7abbfb",
   "metadata": {},
   "source": [
    "At now, the estimator cannot be used as it has not been trained yet, that means that it has no experience. To train the model we call the method `.fit()` which takes the entire training set (both samples and labels) as input and learn the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675abd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape((n_samples, 1)) # scikit-learn requires input to be 2-dim\n",
    "reg.fit(X, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac6594",
   "metadata": {},
   "source": [
    "To assess the training we can first see if the estimated model fits the training data.\n",
    "To do so we need to use the model to predict the labels from the training data, i.e., we use the model for **inference**. In `scikit-learn`, we do it by calling the method `.predict()` which takes the samples as input and returns the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29fbaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(x, y_true, c='C0', label='samples')\n",
    "ax.plot(x, y_gt, c='C1', lw=2, label='true model')\n",
    "ax.plot(x, y_pred, c='C2', lw=2, label='pred model')\n",
    "ax.set(xlabel='$x$', ylabel='$y$')\n",
    "ax.legend()\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be115bc",
   "metadata": {},
   "source": [
    "Better than a visual comparison, we should assess the training with a quantity measure. We have previously choosed the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12990de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_pred = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(f'mse ground-truth: {mse_gt:.3f}')\n",
    "print(f'mse estimator: {mse_pred:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd68dd1",
   "metadata": {},
   "source": [
    "That is a paradox! Our trained model cannot perform better than the ground-truth but it does. How can it be possible?\n",
    "\n",
    "It is because we cannot assess the performance on the training set, we need a test set composed by samples that are different from the training set. Otherwise, it is called cheating!\n",
    "\n",
    "By checking that the MSE in prediction is similar to the one obtained by the ground-truth, we just assess if the estimator was trained enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac02ed",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c08a3d",
   "metadata": {},
   "source": [
    "We need new samples. Since it is a toy case we can generate it.\n",
    "If the dataset is given (as in most real applications), you usually split it into two parts, one for training and the other one for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e35cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.rand(n_samples)\n",
    "y_gt = groud_truth(x)\n",
    "\n",
    "noise = random.randn(n_samples)\n",
    "y_true = y_gt + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape((n_samples, 1))\n",
    "y_pred = reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_gt = mean_squared_error(y_true, y_gt)\n",
    "mse_pred = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(f'mse ground-truth: {mse_gt:.3f}')\n",
    "print(f'mse estimator: {mse_pred:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(x, y_true, c='C0', label='samples')\n",
    "ax.plot(x, y_gt, c='C1', lw=2, label='true model')\n",
    "ax.plot(x, y_pred, c='C2', lw=2, label='pred model')\n",
    "ax.set(xlabel='$x$', ylabel='$y$')\n",
    "ax.legend()\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0554a364",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606be19",
   "metadata": {},
   "source": [
    "We see now a toy case for a classification problem, that consists in finding which class the input data belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f39131",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff47e1",
   "metadata": {},
   "source": [
    "Here, we will make use of one of the datasets available in the `dataset` submodule of `scikit-learn`. In particular, we consider the **hand-written digits dataset** that contains images of hand-written digits and the task consists in identiying which one of the 10 digits the image displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9212ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badde23c",
   "metadata": {},
   "source": [
    "In `scikit-learn`, a dataset is a dictionary-like object that holds all the data and some metadata (that is info about data). This data is stored under the key `data`, which is a (`n_samples`, `n_features`) array. In the case of supervised problem, the dataset also comprises the lables that are stored under the key `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0397508",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data shape', digits['data'].shape)\n",
    "print('labels shape:', digits['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a625d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee4d24",
   "metadata": {},
   "source": [
    "Let's see some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e76b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax in axes:\n",
    "    i_sample = random.randint(0, len(digits.images))\n",
    "    ax.imshow(digits.images[i_sample], cmap=plt.cm.gray_r)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(f\"class: {digits.target[i_sample]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fb46b",
   "metadata": {},
   "source": [
    "Our entire dataset is composed by `n_samples` samples. We cannot use them all for training, otherwise we do not any sample for assessing the performance. Therefore, we first need to split the dataset in **Training** and **Test** sets.\n",
    "\n",
    "To do so, we can use the function `train_test_split` available in the `model_selection` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc40b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.4, shuffle=True\n",
    ")\n",
    "print(f'training -> X: {X_train.shape}, y: {y_train.shape}')\n",
    "print(f'test     -> X: {X_test.shape }, y: {y_test.shape }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffb7ad",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc6b4d",
   "metadata": {},
   "source": [
    "As model we choose the **Support Vector Machine** (**SVM**) that is a common method to address classifgication problems (it was probably the most common before neural networks).\n",
    "We need an estimator that implements the model and is able to learn the parameters from the data that make it perform best.\n",
    "\n",
    "`scikit-learn` dedicates a entire submodule `svm` to SVM since the same underlying principle can be used for other tasks as regression and unsupervised anomaly detection.\n",
    "SVM as classifier is implemented with the estimator `svm.SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19633604",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(gamma=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09705aaa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388719c",
   "metadata": {},
   "source": [
    "Let's train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa89b82",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6a313",
   "metadata": {},
   "source": [
    "To assess the performance of our model we need to choose a quantiative measure and compute it for the predictions on a test set. In classification we have many possible metrics (nearly all of them are available in the `metrics` submodule) and the most common are Accuracy, Precision-Recall, F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60627055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e1a5c4",
   "metadata": {},
   "source": [
    "Here we make the predictions (i.e., inference on the test set) and then compute the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73253b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy: {100*acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7df3c",
   "metadata": {},
   "source": [
    "Accuracy is a good metric but, it little informative about how the model makes mistakes. For this reason, one may have a look at a more informative report on how the model performs for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66312f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499abfd0",
   "metadata": {},
   "source": [
    "Another way to visualize more information about the model performances is the Confusion Matrix, that not only shows how good is classification for each class but also show what are the mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=digits.target_names).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755f269",
   "metadata": {},
   "source": [
    "Let's have a look at some of the most common mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_classes = {'true': 3, 'pred': 7}\n",
    "err_classes = {'true': 5, 'pred': 6}\n",
    "# err_classes = {'true': 5, 'pred': 9}\n",
    "# err_classes = {'true': 8, 'pred': 1}\n",
    "\n",
    "X_err = X_test[(y_test == err_classes['true']) & (y_pred == err_classes['pred'])]\n",
    "\n",
    "nrows, ncols = 1, min(6, len(X_err))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(10, 3), squeeze=False)\n",
    "for ax, x in zip(axes[0], X_err):\n",
    "    image = x.reshape((8,8))\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c2ee7",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
